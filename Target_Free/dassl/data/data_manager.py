import torch
import torchvision.transforms as T
from tabulate import tabulate
from torch.utils.data import Dataset as TorchDataset
import numpy as np
from dassl.utils import read_image

from .datasets import build_dataset
from .samplers import build_sampler
from .transforms import INTERPOLATION_MODES, build_transform, build_transform_lulc
from PIL import Image


def build_data_loader(
    cfg,
    sampler_type="SequentialSampler",
    data_source=None,
    batch_size=64,
    n_domain=0,
    n_ins=2,
    tfm=None,
    is_train=True,
    dataset_wrapper=None,
    mode="norm"
):
    # Build sampler
    sampler = build_sampler(
        sampler_type,
        cfg=cfg,
        data_source=data_source,
        batch_size=batch_size,
        n_domain=n_domain,
        n_ins=n_ins
    )

    if dataset_wrapper is None:
        if mode == "norm" or mode == "free":
            dataset_wrapper = DatasetWrapper
        elif mode == "watermark":
            dataset_wrapper = DatasetWrapper_watermark




    # Build data loader
    data_loader = torch.utils.data.DataLoader(
        dataset_wrapper(cfg, data_source, transform=tfm, is_train=is_train),
        batch_size=batch_size,
        sampler=sampler,
        num_workers=cfg.DATALOADER.NUM_WORKERS,
        drop_last=is_train and len(data_source) >= batch_size,
        pin_memory=(torch.cuda.is_available() and cfg.USE_CUDA)
    )
    assert len(data_loader) > 0

    return data_loader



# 資料管理主類別，負責根據 config 初始化各種 train/test/val dataloader
class DataManager:

    def __init__(
        self,
        cfg,
        custom_tfm_train=None,
        custom_tfm_test=None,
        dataset_wrapper=None
    ):

        # 載入資料集（根據 config 設定的 dataset 類型）
        dataset = build_dataset(cfg)


        # 建立各種 augmentation pipeline
        # tfm_train_x: 給 source domain (授權/本公司風格)
        # tfm_train_u: 給 target domain (未授權/一般風格)
        # tfm_test_authorized: 測試集 aggressive augmentation（授權風格）
        # tfm_test_unauthorized: 測試集 mild augmentation（一般風格）
        tfm_train_x = None
        tfm_train_u = None
        tfm_test_authorized = None
        tfm_test_unauthorized = None

        if "lulc_ip" in cfg.INPUT.TRANSFORMS:
            print("* Using LULC IP Protection transforms")
            # 訓練集：source domain 用 aggressive augmentation，target domain 用 mild augmentation
            tfm_train_x = build_transform_lulc(cfg, is_source=True)      # 授權風格
            tfm_train_u = build_transform_lulc(cfg, is_source=False)     # 未授權風格
            # 測試集：test1 用 aggressive（授權），test2 用 mild（一般）
            tfm_test_authorized = build_transform_lulc(cfg, is_source=True)
            tfm_test_unauthorized = build_transform_lulc(cfg, is_source=False)
            # 預設 test loader 用 mild augmentation（模擬真實世界/未授權）
            tfm_test = tfm_test_unauthorized 
        else:
            if custom_tfm_train is None:
                tfm_train = build_transform(cfg, is_train=True)
            else:
                print("* Using custom transform for training")
                tfm_train = custom_tfm_train
            tfm_train_x = tfm_train
            tfm_train_u = tfm_train

            if custom_tfm_test is None:
                tfm_test = build_transform(cfg)
            else:
                print("* Using custom transform for testing")
                tfm_test = custom_tfm_test


        # 若 test mode 設為 free，會額外建立一組 free-style augmentation
        if cfg.DATALOADER.TEST.MODE == "free":
            tfm_free = build_transform(cfg, is_free=True)


        # 建立 source domain 訓練 dataloader（授權/本公司風格）
        train_loader_x = build_data_loader(
            cfg,
            sampler_type=cfg.DATALOADER.TRAIN_X.SAMPLER,
            data_source=dataset.train_x,
            batch_size=cfg.DATALOADER.TRAIN_X.BATCH_SIZE,
            n_domain=cfg.DATALOADER.TRAIN_X.N_DOMAIN,
            n_ins=cfg.DATALOADER.TRAIN_X.N_INS,
            tfm=tfm_train_x,
            is_train=True,
            dataset_wrapper=dataset_wrapper
        )


        # 測試集 dataloader（通常用 mild augmentation，模擬真實世界）
        test_loader_x = build_data_loader(
            cfg,
            sampler_type=cfg.DATALOADER.TEST.SAMPLER,
            data_source=dataset.test_x,
            batch_size=cfg.DATALOADER.TEST.BATCH_SIZE,
            tfm=tfm_test,
            is_train=False,
            dataset_wrapper=dataset_wrapper
        )


        # 建立 target domain 訓練 dataloader（未授權/一般風格）
        train_loader_u = None
        if dataset.train_u:
            sampler_type_ = cfg.DATALOADER.TRAIN_U.SAMPLER
            batch_size_ = cfg.DATALOADER.TRAIN_U.BATCH_SIZE
            n_domain_ = cfg.DATALOADER.TRAIN_U.N_DOMAIN
            n_ins_ = cfg.DATALOADER.TRAIN_U.N_INS

            # 若 SAME_AS_X，則 target domain 設定與 source 相同
            #if cfg.DATALOADER.TRAIN_U.SAME_AS_X:
            #    sampler_type_ = cfg.DATALOADER.TRAIN_X.SAMPLER
            #    batch_size_ = cfg.DATALOADER.TRAIN_X.BATCH_SIZE
            #    n_domain_ = cfg.DATALOADER.TRAIN_X.N_DOMAIN
            #    n_ins_ = cfg.DATALOADER.TRAIN_X.N_INS
            
            
            # 若 test mode 為 free 且沒用 lulc_ip，target domain 用 free augmentation
            if cfg.DATALOADER.TEST.MODE == "free" and "lulc_ip" not in cfg.INPUT.TRANSFORMS:
                train_loader_u = build_data_loader(
                    cfg,
                    sampler_type=sampler_type_,
                    data_source=dataset.train_u,
                    batch_size=batch_size_,
                    n_domain=n_domain_,
                    n_ins=n_ins_,
                    tfm=tfm_free,
                    is_train=True,
                    dataset_wrapper=dataset_wrapper,
                    mode=cfg.DATALOADER.TEST.MODE
                )
            else:
                train_loader_u = build_data_loader(
                    cfg,
                    sampler_type=sampler_type_,
                    data_source=dataset.train_u,
                    batch_size=batch_size_,
                    n_domain=n_domain_,
                    n_ins=n_ins_,
                    tfm=tfm_train_u,
                    is_train=True,
                    dataset_wrapper=dataset_wrapper,
                    mode=cfg.DATALOADER.TEST.MODE
                )


        # 驗證集 dataloader（通常用 mild augmentation）
        val_loader = None
        if dataset.val:
            val_loader = build_data_loader(
                cfg,
                sampler_type=cfg.DATALOADER.TEST.SAMPLER,
                data_source=dataset.val,
                batch_size=cfg.DATALOADER.TEST.BATCH_SIZE,
                tfm=tfm_test,
                is_train=False,
                dataset_wrapper=dataset_wrapper
            )


        # 未授權測試集 dataloader（通常用 mild augmentation）
        test_loader_u = build_data_loader(
            cfg,
            sampler_type=cfg.DATALOADER.TEST.SAMPLER,
            data_source=dataset.test_u,
            batch_size=cfg.DATALOADER.TEST.BATCH_SIZE,
            tfm=tfm_test,
            is_train=False,
            dataset_wrapper=dataset_wrapper,
            mode=cfg.DATALOADER.TEST.MODE
        )


        # 測試集 loader 初始化（free 模式下可同時建立兩種風格的 test set）
        if cfg.DATALOADER.TEST.MODE == "free":
            if "lulc_ip" in cfg.INPUT.TRANSFORMS and tfm_test_authorized is not None:
                print("* Creating Dual Test Sets for LULC IP Verification (Free Mode)")
                # test_loader_1: 授權風格（aggressive augmentation）
                test_loader_1 = build_data_loader(
                    cfg,
                    sampler_type=cfg.DATALOADER.TEST.SAMPLER,
                    data_source=dataset.test_1, # Using test_1 data
                    batch_size=cfg.DATALOADER.TEST.BATCH_SIZE,
                    tfm=tfm_test_authorized, # Authorized Transform
                    is_train=False,
                    dataset_wrapper=dataset_wrapper,
                    mode=cfg.DATALOADER.TEST.MODE
                )
                # test_loader_2: 一般風格（mild augmentation）
                test_loader_2 = build_data_loader(
                    cfg,
                    sampler_type=cfg.DATALOADER.TEST.SAMPLER,
                    data_source=dataset.test_2, # Using test_2 data
                    batch_size=cfg.DATALOADER.TEST.BATCH_SIZE,
                    tfm=tfm_test_unauthorized, # Unauthorized Transform
                    is_train=False,
                    dataset_wrapper=dataset_wrapper,
                    mode=cfg.DATALOADER.TEST.MODE
                )
            else:
                # 沒有 lulc_ip 時，兩個 test set 都用 mild augmentation
                test_loader_1 = build_data_loader(
                    cfg,
                    sampler_type=cfg.DATALOADER.TEST.SAMPLER,
                    data_source=dataset.test_1,
                    batch_size=cfg.DATALOADER.TEST.BATCH_SIZE,
                    tfm=tfm_test,
                    is_train=False,
                    dataset_wrapper=dataset_wrapper,
                    mode=cfg.DATALOADER.TEST.MODE
                )

                test_loader_2 = build_data_loader(
                    cfg,
                    sampler_type=cfg.DATALOADER.TEST.SAMPLER,
                    data_source=dataset.test_2,
                    batch_size=cfg.DATALOADER.TEST.BATCH_SIZE,
                    tfm=tfm_test,
                    is_train=False,
                    dataset_wrapper=dataset_wrapper,
                    mode=cfg.DATALOADER.TEST.MODE
                )
            # 設定屬性，方便外部 trainer 直接存取
            self.test_loader_1 = test_loader_1
            self.test_loader_2 = test_loader_2
            # 其他 test loader 預設為 None
            self.test_loader_3 = None
            self.test_loader_4 = None
        elif cfg.DATALOADER.TEST.MODE == "watermark":
            test_loader_1 = build_data_loader(
                cfg,
                sampler_type=cfg.DATALOADER.TEST.SAMPLER,
                data_source=dataset.test_1,
                batch_size=cfg.DATALOADER.TEST.BATCH_SIZE,
                tfm=tfm_test,
                is_train=False,
                dataset_wrapper=dataset_wrapper
            )
            test_loader_2 = build_data_loader(
                cfg,
                sampler_type=cfg.DATALOADER.TEST.SAMPLER,
                data_source=dataset.test_2,
                batch_size=cfg.DATALOADER.TEST.BATCH_SIZE,
                tfm=tfm_test,
                is_train=False,
                dataset_wrapper=dataset_wrapper
            )

            test_loader_3 = build_data_loader(
                cfg,
                sampler_type=cfg.DATALOADER.TEST.SAMPLER,
                data_source=dataset.test_3,
                batch_size=cfg.DATALOADER.TEST.BATCH_SIZE,
                tfm=tfm_test,
                is_train=False,
                dataset_wrapper=dataset_wrapper,
                mode=cfg.DATALOADER.TEST.MODE
            )

            test_loader_4 = build_data_loader(
                cfg,
                sampler_type=cfg.DATALOADER.TEST.SAMPLER,
                data_source=dataset.test_4,
                batch_size=cfg.DATALOADER.TEST.BATCH_SIZE,
                tfm=tfm_test,
                is_train=False,
                dataset_wrapper=dataset_wrapper,
                mode=cfg.DATALOADER.TEST.MODE
            )
            self.test_loader_1 = test_loader_1
            self.test_loader_2 = test_loader_2
            self.test_loader_3 = test_loader_3
            self.test_loader_4 = test_loader_4


        # 重要屬性：類別數、domain 數、label->class name 對應
        self._num_classes = dataset.num_classes
        self._num_source_domains = len(cfg.DATASET.SOURCE_DOMAINS)
        self._lab2cname = dataset.lab2cname

        # 重要屬性：資料集本體與各種 dataloader
        self.dataset = dataset
        self.train_loader_x = train_loader_x
        self.train_loader_u = train_loader_u
        self.val_loader = val_loader
        self.test_loader_x = test_loader_x
        self.test_loader_u = test_loader_u

        if cfg.VERBOSE:
            self.show_dataset_summary(cfg)

    @property
    def num_classes(self):
        return self._num_classes

    @property
    def num_source_domains(self):
        return self._num_source_domains

    @property
    def lab2cname(self):
        return self._lab2cname

    # 印出資料集摘要，方便 debug 與報告
    def show_dataset_summary(self, cfg):
        dataset_name = cfg.DATASET.NAME
        source_domains = cfg.DATASET.SOURCE_DOMAINS
        target_domains = cfg.DATASET.TARGET_DOMAINS

        table = []
        table.append(["Dataset", dataset_name])
        if source_domains:
            table.append(["Source", source_domains])
        if target_domains:
            table.append(["Target", target_domains])
        table.append(["# classes", f"{self.num_classes:,}"])
        table.append(["# train_x", f"{len(self.dataset.train_x):,}"])
        if self.dataset.train_u:
            table.append(["# train_u", f"{len(self.dataset.train_u):,}"])
        if self.dataset.val:
            table.append(["# val", f"{len(self.dataset.val):,}"])
        table.append(["# test_x", f"{len(self.dataset.test_x):,}"])
        table.append(["# test_u", f"{len(self.dataset.test_u):,}"])

        print(tabulate(table))


class DatasetWrapper(TorchDataset):

    def __init__(self, cfg, data_source, transform=None, is_train=False):
        self.cfg = cfg
        self.data_source = data_source
        self.transform = transform  # accept list (tuple) as input
        self.is_train = is_train
        # Augmenting an image K>1 times is only allowed during training
        self.k_tfm = cfg.DATALOADER.K_TRANSFORMS if is_train else 1
        self.return_img0 = cfg.DATALOADER.RETURN_IMG0

        if self.k_tfm > 1 and transform is None:
            raise ValueError(
                "Cannot augment the image {} times "
                "because transform is None".format(self.k_tfm)
            )

        # Build transform that doesn't apply any data augmentation
        interp_mode = INTERPOLATION_MODES[cfg.INPUT.INTERPOLATION]
        to_tensor = []
        to_tensor += [T.Resize(cfg.INPUT.SIZE, interpolation=interp_mode)]
        to_tensor += [T.ToTensor()]
        if "normalize" in cfg.INPUT.TRANSFORMS:
            normalize = T.Normalize(
                mean=cfg.INPUT.PIXEL_MEAN, std=cfg.INPUT.PIXEL_STD
            )
            to_tensor += [normalize]
        self.to_tensor = T.Compose(to_tensor)

    def __len__(self):
        return len(self.data_source)

    def __getitem__(self, idx):
        item = self.data_source[idx]

        output = {
            "label": item.label,
            "domain": item.domain,
            "impath": item.impath,
            "index": idx
        }

        img0 = read_image(item.impath)

        if self.transform is not None:
            if isinstance(self.transform, (list, tuple)):
                for i, tfm in enumerate(self.transform):
                    img = self._transform_image(tfm, img0)
                    keyname = "img"
                    if (i + 1) > 1:
                        keyname += str(i + 1)
                    output[keyname] = img
            else:
                img = self._transform_image(self.transform, img0)
                output["img"] = img
        else:
            output["img"] = img0

        if self.return_img0:
            output["img0"] = self.to_tensor(img0)  # without any augmentation

        return output

    def _transform_image(self, tfm, img0):
        img_list = []

        for k in range(self.k_tfm):
            img_list.append(tfm(img0))

        img = img_list
        if len(img) == 1:
            img = img[0]

        return img


class DatasetWrapper_watermark(TorchDataset):

    def __init__(self, cfg, data_source, transform=None, is_train=False):
        self.cfg = cfg
        self.data_source = data_source
        self.transform = transform  # accept list (tuple) as input
        self.is_train = is_train
        # Augmenting an image K>1 times is only allowed during training
        self.k_tfm = cfg.DATALOADER.K_TRANSFORMS if is_train else 1
        self.return_img0 = cfg.DATALOADER.RETURN_IMG0

        if self.k_tfm > 1 and transform is None:
            raise ValueError(
                "Cannot augment the image {} times "
                "because transform is None".format(self.k_tfm)
            )

        # Build transform that doesn't apply any data augmentation
        interp_mode = INTERPOLATION_MODES[cfg.INPUT.INTERPOLATION]
        to_tensor = []
        to_tensor += [T.Resize(cfg.INPUT.SIZE, interpolation=interp_mode)]
        to_tensor += [T.ToTensor()]
        if "normalize" in cfg.INPUT.TRANSFORMS:
            normalize = T.Normalize(
                mean=cfg.INPUT.PIXEL_MEAN, std=cfg.INPUT.PIXEL_STD
            )
            to_tensor += [normalize]
        self.to_tensor = T.Compose(to_tensor)

    def __len__(self):
        return len(self.data_source)

    def __getitem__(self, idx):
        item = self.data_source[idx]

        output = {
            "label": item.label,
            "domain": item.domain,
            "impath": item.impath,
            "index": idx
        }

        img0 = read_image(item.impath)
        img0 = self._add_watermark(img0)

        if self.transform is not None:
            if isinstance(self.transform, (list, tuple)):
                for i, tfm in enumerate(self.transform):
                    img = self._transform_image(tfm, img0)
                    keyname = "img"
                    if (i + 1) > 1:
                        keyname += str(i + 1)
                    output[keyname] = img
            else:
                img = self._transform_image(self.transform, img0)
                output["img"] = img
        else:
            output["img"] = img0

        if self.return_img0:
            output["img0"] = self.to_tensor(img0)  # without any augmentation

        return output

    def _transform_image(self, tfm, img0):
        img_list = []

        for k in range(self.k_tfm):
            img_list.append(tfm(img0))

        img = img_list
        if len(img) == 1:
            img = img[0]

        return img

    def _add_watermark(self, img0):
        img_array = np.array(img0)
        mask = np.zeros(img_array.shape[:2])
        for i in range(mask.shape[0]):
            for j in range(mask.shape[1]):
                if i % 2 == 0 or j % 2 == 0:
                    mask[i, j] = 255
        img_mask = np.minimum(img_array.astype(int) + mask[:,:,np.newaxis].astype(int), 255).astype(np.uint8)
        img_mask = Image.fromarray(img_mask)
        return img_mask


class DatasetWrapper_free(TorchDataset):

    def __init__(self, cfg, data_source, transform=None, is_train=False):
        self.cfg = cfg
        self.data_source = data_source
        self.transform = transform  # accept list (tuple) as input
        self.is_train = is_train
        # Augmenting an image K>1 times is only allowed during training
        self.k_tfm = cfg.DATALOADER.K_TRANSFORMS if is_train else 1
        self.return_img0 = cfg.DATALOADER.RETURN_IMG0

        if self.k_tfm > 1 and transform is None:
            raise ValueError(
                "Cannot augment the image {} times "
                "because transform is None".format(self.k_tfm)
            )

        # Build transform that doesn't apply any data augmentation
        interp_mode = INTERPOLATION_MODES[cfg.INPUT.INTERPOLATION]
        to_tensor = []
        to_tensor += [T.Resize(cfg.INPUT.SIZE, interpolation=interp_mode)]
        to_tensor += [T.ToTensor()]
        if "normalize" in cfg.INPUT.TRANSFORMS:
            normalize = T.Normalize(
                mean=cfg.INPUT.PIXEL_MEAN, std=cfg.INPUT.PIXEL_STD
            )
            to_tensor += [normalize]
        self.to_tensor = T.Compose(to_tensor)

    def __len__(self):
        return len(self.data_source)

    def __getitem__(self, idx):
        item = self.data_source[idx]

        output = {
            "label": item.label,
            "domain": item.domain,
            "impath": item.impath,
            "index": idx
        }

        img0 = read_image(item.impath)

        print('self.transform', self.transform)

        if self.transform is not None:
            if isinstance(self.transform, (list, tuple)):
                for i, tfm in enumerate(self.transform):
                    img = self._transform_image(tfm, img0)
                    keyname = "img"
                    if (i + 1) > 1:
                        keyname += str(i + 1)
                    output[keyname] = img
            else:
                img = self._transform_image(self.transform, img0)
                output["img"] = img
        else:
            output["img"] = img0

        if self.return_img0:
            output["img0"] = self.to_tensor(img0)  # without any augmentation

        return output

    def _transform_image(self, tfm, img0):
        img_list = []

        for k in range(self.k_tfm):
            img_list.append(tfm(img0))

        img = img_list
        if len(img) == 1:
            img = img[0]

        return img